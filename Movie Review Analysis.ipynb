{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis Of Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133399</th>\n",
       "      <td>133400</td>\n",
       "      <td>7198</td>\n",
       "      <td>at last count</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54873</th>\n",
       "      <td>54874</td>\n",
       "      <td>2733</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>15028</td>\n",
       "      <td>646</td>\n",
       "      <td>while it may not rival the filmmaker 's period...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109195</th>\n",
       "      <td>109196</td>\n",
       "      <td>5782</td>\n",
       "      <td>conventional , but</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47891</th>\n",
       "      <td>47892</td>\n",
       "      <td>2335</td>\n",
       "      <td>that would be foreign in American teen comedies</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "133399    133400        7198   \n",
       "54873      54874        2733   \n",
       "15027      15028         646   \n",
       "109195    109196        5782   \n",
       "47891      47892        2335   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "133399                                      at last count          2  \n",
       "54873                                              Snacks          2  \n",
       "15027   while it may not rival the filmmaker 's period...          2  \n",
       "109195                                 conventional , but          2  \n",
       "47891     that would be foreign in American teen comedies          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.tsv', delimiter = '\\t')\n",
    "print(train.shape)\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62134</th>\n",
       "      <td>218195</td>\n",
       "      <td>11624</td>\n",
       "      <td>the first sci-fi comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41380</th>\n",
       "      <td>197441</td>\n",
       "      <td>10501</td>\n",
       "      <td>as an intense , brooding character study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21488</th>\n",
       "      <td>177549</td>\n",
       "      <td>9505</td>\n",
       "      <td>bored or frustrated by the film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>163030</td>\n",
       "      <td>8817</td>\n",
       "      <td>Too leisurely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25976</th>\n",
       "      <td>182037</td>\n",
       "      <td>9726</td>\n",
       "      <td>this sad-sack waste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                    Phrase\n",
       "62134    218195       11624                   the first sci-fi comedy\n",
       "41380    197441       10501  as an intense , brooding character study\n",
       "21488    177549        9505           bored or frustrated by the film\n",
       "6969     163030        8817                             Too leisurely\n",
       "25976    182037        9726                       this sad-sack waste"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.tsv', delimiter = '\\t')\n",
    "print(test.shape)\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37170</th>\n",
       "      <td>193231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58938</th>\n",
       "      <td>214999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15371</th>\n",
       "      <td>171432</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59049</th>\n",
       "      <td>215110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61669</th>\n",
       "      <td>217730</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  Sentiment\n",
       "37170    193231          2\n",
       "58938    214999          2\n",
       "15371    171432          2\n",
       "59049    215110          2\n",
       "61669    217730          2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_csv('samplesubmission.csv')\n",
    "print(samples.shape)\n",
    "samples.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding trian and test for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222352, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23893</th>\n",
       "      <td>179954</td>\n",
       "      <td>9620</td>\n",
       "      <td>deepen</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>4323</td>\n",
       "      <td>164</td>\n",
       "      <td>bet there is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132775</th>\n",
       "      <td>132776</td>\n",
       "      <td>7159</td>\n",
       "      <td>world dichotomy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110218</th>\n",
       "      <td>110219</td>\n",
       "      <td>5837</td>\n",
       "      <td>proverbial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120427</th>\n",
       "      <td>120428</td>\n",
       "      <td>6439</td>\n",
       "      <td>Anna Mouglalis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId           Phrase  Sentiment\n",
       "23893     179954        9620           deepen         -1\n",
       "4322        4323         164     bet there is          2\n",
       "132775    132776        7159  world dichotomy          2\n",
       "110218    110219        5837       proverbial          2\n",
       "120427    120428        6439   Anna Mouglalis          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Sentiment'] = -1\n",
    "df = pd.concat((train,test))\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating function to clean reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_clean(all_reviews):\n",
    "    corpus = []\n",
    "    for i in range(0, len(all_reviews)):\n",
    "        review = str(all_reviews[i])\n",
    "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "        review = [stemmer.stem(word) for word in word_tokenize(str(review).lower())]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = review_clean(df.Phrase.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145016</th>\n",
       "      <td>145017</td>\n",
       "      <td>7876</td>\n",
       "      <td>during the first hour</td>\n",
       "      <td>2</td>\n",
       "      <td>dure the first hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146672</th>\n",
       "      <td>146673</td>\n",
       "      <td>7979</td>\n",
       "      <td>of watching this film with an audience full of...</td>\n",
       "      <td>1</td>\n",
       "      <td>of watch this film with an audienc full of tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121777</th>\n",
       "      <td>121778</td>\n",
       "      <td>6525</td>\n",
       "      <td>deserves more</td>\n",
       "      <td>2</td>\n",
       "      <td>deserv more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18357</th>\n",
       "      <td>174418</td>\n",
       "      <td>9356</td>\n",
       "      <td>to any actress I can remember to personifying ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>to ani actress i can rememb to personifi indep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31342</th>\n",
       "      <td>187403</td>\n",
       "      <td>9992</td>\n",
       "      <td>lend its imprimatur to , then perhaps</td>\n",
       "      <td>-1</td>\n",
       "      <td>lend it imprimatur to then perhap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "145016    145017        7876   \n",
       "146672    146673        7979   \n",
       "121777    121778        6525   \n",
       "18357     174418        9356   \n",
       "31342     187403        9992   \n",
       "\n",
       "                                                   Phrase  Sentiment  \\\n",
       "145016                              during the first hour          2   \n",
       "146672  of watching this film with an audience full of...          1   \n",
       "121777                                      deserves more          2   \n",
       "18357   to any actress I can remember to personifying ...         -1   \n",
       "31342               lend its imprimatur to , then perhaps         -1   \n",
       "\n",
       "                                           cleaned_review  \n",
       "145016                                dure the first hour  \n",
       "146672  of watch this film with an audienc full of tee...  \n",
       "121777                                        deserv more  \n",
       "18357   to ani actress i can rememb to personifi indep...  \n",
       "31342                   lend it imprimatur to then perhap  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62744</th>\n",
       "      <td>218805</td>\n",
       "      <td>11657</td>\n",
       "      <td>` urban comedy '</td>\n",
       "      <td>urban comedi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64442</th>\n",
       "      <td>220503</td>\n",
       "      <td>11746</td>\n",
       "      <td>are so heavy-handed that they instead pummel t...</td>\n",
       "      <td>are so heavi hand that they instead pummel the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14750</th>\n",
       "      <td>170811</td>\n",
       "      <td>9179</td>\n",
       "      <td>on the small screen</td>\n",
       "      <td>on the small screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34480</th>\n",
       "      <td>190541</td>\n",
       "      <td>10155</td>\n",
       "      <td>of coming-of-age cliches</td>\n",
       "      <td>of come of age clich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65634</th>\n",
       "      <td>221695</td>\n",
       "      <td>11812</td>\n",
       "      <td>it 's now coming true ' bad</td>\n",
       "      <td>it s now come true bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId  \\\n",
       "62744    218805       11657   \n",
       "64442    220503       11746   \n",
       "14750    170811        9179   \n",
       "34480    190541       10155   \n",
       "65634    221695       11812   \n",
       "\n",
       "                                                  Phrase  \\\n",
       "62744                                   ` urban comedy '   \n",
       "64442  are so heavy-handed that they instead pummel t...   \n",
       "14750                                on the small screen   \n",
       "34480                           of coming-of-age cliches   \n",
       "65634                        it 's now coming true ' bad   \n",
       "\n",
       "                                          cleaned_review  \n",
       "62744                                       urban comedi  \n",
       "64442  are so heavi hand that they instead pummel the...  \n",
       "14750                                on the small screen  \n",
       "34480                               of come of age clich  \n",
       "65634                             it s now come true bad  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df.Sentiment != -1]\n",
    "df_test = df[df.Sentiment == -1]\n",
    "df_test.drop('Sentiment', axis = 1).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132725</th>\n",
       "      <td>132726</td>\n",
       "      <td>7155</td>\n",
       "      <td>just copies</td>\n",
       "      <td>1</td>\n",
       "      <td>just copi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053</th>\n",
       "      <td>24054</td>\n",
       "      <td>1093</td>\n",
       "      <td>can thank me for this</td>\n",
       "      <td>2</td>\n",
       "      <td>can thank me for this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119010</th>\n",
       "      <td>119011</td>\n",
       "      <td>6361</td>\n",
       "      <td>the love scenes all end in someone screaming .</td>\n",
       "      <td>2</td>\n",
       "      <td>the love scene all end in someon scream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>13471</td>\n",
       "      <td>580</td>\n",
       "      <td>This is n't a stand up and cheer flick ;</td>\n",
       "      <td>2</td>\n",
       "      <td>this is n t a stand up and cheer flick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26743</th>\n",
       "      <td>26744</td>\n",
       "      <td>1226</td>\n",
       "      <td>subtle ironies</td>\n",
       "      <td>3</td>\n",
       "      <td>subtl ironi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                                          Phrase  \\\n",
       "132725    132726        7155                                     just copies   \n",
       "24053      24054        1093                           can thank me for this   \n",
       "119010    119011        6361  the love scenes all end in someone screaming .   \n",
       "13470      13471         580        This is n't a stand up and cheer flick ;   \n",
       "26743      26744        1226                                  subtle ironies   \n",
       "\n",
       "        Sentiment                           cleaned_review  \n",
       "132725          1                                just copi  \n",
       "24053           2                    can thank me for this  \n",
       "119010          2  the love scene all end in someon scream  \n",
       "13470           2   this is n t a stand up and cheer flick  \n",
       "26743           3                              subtl ironi  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59855</th>\n",
       "      <td>215916</td>\n",
       "      <td>11502</td>\n",
       "      <td>heard since Macy Gray 's game of Chinese whisp...</td>\n",
       "      <td>-1</td>\n",
       "      <td>heard sinc maci gray s game of chines whisper ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34744</th>\n",
       "      <td>190805</td>\n",
       "      <td>10168</td>\n",
       "      <td>difficult-to-swallow</td>\n",
       "      <td>-1</td>\n",
       "      <td>difficult to swallow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19849</th>\n",
       "      <td>175910</td>\n",
       "      <td>9424</td>\n",
       "      <td>modern context</td>\n",
       "      <td>-1</td>\n",
       "      <td>modern context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23601</th>\n",
       "      <td>179662</td>\n",
       "      <td>9607</td>\n",
       "      <td>correctness</td>\n",
       "      <td>-1</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11131</th>\n",
       "      <td>167192</td>\n",
       "      <td>9005</td>\n",
       "      <td>is n't a weak or careless performance amongst ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>is n t a weak or careless perform amongst them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId  \\\n",
       "59855    215916       11502   \n",
       "34744    190805       10168   \n",
       "19849    175910        9424   \n",
       "23601    179662        9607   \n",
       "11131    167192        9005   \n",
       "\n",
       "                                                  Phrase  Sentiment  \\\n",
       "59855  heard since Macy Gray 's game of Chinese whisp...         -1   \n",
       "34744                               difficult-to-swallow         -1   \n",
       "19849                                     modern context         -1   \n",
       "23601                                        correctness         -1   \n",
       "11131  is n't a weak or careless performance amongst ...         -1   \n",
       "\n",
       "                                          cleaned_review  \n",
       "59855  heard sinc maci gray s game of chines whisper ...  \n",
       "34744                               difficult to swallow  \n",
       "19849                                     modern context  \n",
       "23601                                            correct  \n",
       "11131     is n t a weak or careless perform amongst them  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries to process further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence,text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Conv1D, GlobalMaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.cleaned_review.values\n",
    "test = df_test.cleaned_review\n",
    "y = to_categorical(df_train.Sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n",
      "(66292,)\n",
      "(156060, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting training set into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y, stratify = y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848,) (31212,) (66292,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of unique words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10341\n"
     ]
    }
   ],
   "source": [
    "total_words = ' '.join(X_train)\n",
    "total_words = word_tokenize(total_words)\n",
    "unique_words = FreqDist(total_words)\n",
    "max_features = len(unique_words)\n",
    "print(max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum length of review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "review_len = []\n",
    "for text in X_train:\n",
    "    word = word_tokenize(text)\n",
    "    l = len(word)\n",
    "    review_len.append(l)\n",
    "max_review_len = np.max(review_len)\n",
    "print(max_review_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_len)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=max_review_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Saini\\Anaconda3\\envs\\Python3.6Test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Mohit Saini\\Anaconda3\\envs\\Python3.6Test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "classifier= Sequential()\n",
    "classifier.add(Embedding(max_features, 100, input_length=max_review_len))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Conv1D(64, kernel_size=3, padding='same', activation='relu', strides=1))\n",
    "classifier.add(GlobalMaxPooling1D())\n",
    "\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 48, 100)           1034100   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 48, 64)            19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,062,329\n",
      "Trainable params: 1,062,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Saini\\Anaconda3\\envs\\Python3.6Test\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Mohit Saini\\Anaconda3\\envs\\Python3.6Test\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/3\n",
      "124848/124848 [==============================] - 100s 801us/step - loss: 1.0089 - acc: 0.5968 - val_loss: 0.8476 - val_acc: 0.6488\n",
      "Epoch 2/3\n",
      "124848/124848 [==============================] - 71s 565us/step - loss: 0.7932 - acc: 0.6732 - val_loss: 0.8048 - val_acc: 0.6664\n",
      "Epoch 3/3\n",
      "124848/124848 [==============================] - 66s 531us/step - loss: 0.7178 - acc: 0.7012 - val_loss: 0.7997 - val_acc: 0.6665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159a31c25c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66292/66292 [==============================] - 6s 95us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict_classes(X_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6Test",
   "language": "python",
   "name": "python3.6test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
